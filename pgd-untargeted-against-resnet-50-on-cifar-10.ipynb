{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":3840.361324,"end_time":"2023-06-19T07:19:02.571784","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-06-19T06:15:02.210460","version":"2.4.0"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5964993,"sourceType":"datasetVersion","datasetId":3420584},{"sourceId":6283699,"sourceType":"datasetVersion","datasetId":3613289}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Projected Gradient Descent against ResNet-50 on CIFAR-10 (Untargeted)\n\nIn summary, the ResNet-50 pretrained on ImageNet is fine-tuned for CIFAR-10 dataset. The robustness of this fine-tuned model is then tested against adversarial examples generated by the Projected Gradient Descent attack.\n\nRead my blog post on the same here: [Part 3 - Projected Gradient Descent (PGD)](https://sidthoviti.com/part-3-projected-gradient-descent-pgd/)\n\n## Importing Libraries\n\nLet's import all the libraries required to run this project.","metadata":{"id":"YU0QTfcyx4Ef","papermill":{"duration":0.011051,"end_time":"2023-06-19T06:15:14.077308","exception":false,"start_time":"2023-06-19T06:15:14.066257","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random","metadata":{"id":"_8TlFZxziBEt","papermill":{"duration":4.527886,"end_time":"2023-06-19T06:15:18.615213","exception":false,"start_time":"2023-06-19T06:15:14.087327","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:24.757388Z","iopub.execute_input":"2024-05-27T07:51:24.757783Z","iopub.status.idle":"2024-05-27T07:51:30.452141Z","shell.execute_reply.started":"2024-05-27T07:51:24.757755Z","shell.execute_reply":"2024-05-27T07:51:30.451357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the Dataset\n\nNext, we’ll write a function that is responsible for loading the CIFAR-10 dataset, preprocessing the data, and setting up the train and test dataloaders.\n\nThe function defines a tuple of classes names corresponding to the 10 classes in the CIFAR-10 dataset, and returns the train and test sets, their respective data loaders and classes.","metadata":{"id":"L8FNpHKgy83Z","papermill":{"duration":0.006618,"end_time":"2023-06-19T06:15:18.629963","exception":false,"start_time":"2023-06-19T06:15:18.623345","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def load_dataset(batch_size):\n    # Set dataset path\n    dataset_path = './data/cifar10'\n\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n\n    # Load CIFAR-10 dataset\n    trainset = torchvision.datasets.CIFAR10(root=dataset_path, train=True,\n                                            download=True, transform=transform_train)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n                                              shuffle=True, num_workers=2)\n\n    testset = torchvision.datasets.CIFAR10(root=dataset_path, train=False,\n                                           download=True, transform=transform_test)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n                                             shuffle=False, num_workers=2)\n\n    # Class names for CIFAR-10 dataset\n    classes = ('plane', 'car', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck')\n\n    return trainset, trainloader, testset, testloader, classes\n","metadata":{"id":"ytJm4D2kiMkT","papermill":{"duration":0.020241,"end_time":"2023-06-19T06:15:18.657305","exception":false,"start_time":"2023-06-19T06:15:18.637064","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.454014Z","iopub.execute_input":"2024-05-27T07:51:30.454981Z","iopub.status.idle":"2024-05-27T07:51:30.463467Z","shell.execute_reply.started":"2024-05-27T07:51:30.454946Z","shell.execute_reply":"2024-05-27T07:51:30.462594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model\n\nOnce the datasets are loaded and dataloaders are initialized, we can proceed to train the model.\n\nThe “train” function is responsible for training the model on the CIFAR-10 dataset. The function performs the training loop for one epoch and returns the updated model parameters, training loss, and training accuracy. It initializes some variables to keep track of the loss and accuracy.","metadata":{"id":"s_X6r4KtzR2f","papermill":{"duration":0.006877,"end_time":"2023-06-19T06:15:18.671202","exception":false,"start_time":"2023-06-19T06:15:18.664325","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train(model, trainloader, criterion, optimizer, device):\n    train_loss = 0.0\n    train_total = 0\n    train_correct = 0\n\n    # Switch to train mode\n    model.train()\n\n    for inputs, labels in trainloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        # Update training loss\n        train_loss += loss.item() * inputs.size(0)\n\n        # Compute training accuracy\n        _, predicted = torch.max(outputs, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n\n    # Compute average training loss and accuracy\n    train_loss = train_loss / len(trainloader.dataset)\n    train_accuracy = 100.0 * train_correct / train_total\n\n    return model, train_loss, train_accuracy","metadata":{"id":"uwRGQmt0iVRR","papermill":{"duration":0.018107,"end_time":"2023-06-19T06:15:18.696653","exception":false,"start_time":"2023-06-19T06:15:18.678546","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.464814Z","iopub.execute_input":"2024-05-27T07:51:30.465070Z","iopub.status.idle":"2024-05-27T07:51:30.475736Z","shell.execute_reply.started":"2024-05-27T07:51:30.465049Z","shell.execute_reply":"2024-05-27T07:51:30.474907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the Model\n\nThe “test” function evaluates the model on the test set and returns the test loss and accuracy.","metadata":{"id":"pTAPiWVhzbou","papermill":{"duration":0.006434,"end_time":"2023-06-19T06:15:18.709786","exception":false,"start_time":"2023-06-19T06:15:18.703352","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def test(model, testloader, criterion, device):\n    test_loss = 0.0\n    test_total = 0\n    test_correct = 0\n\n    # Switch to evaluation mode\n    model.eval()\n\n    with torch.no_grad():\n        for inputs, labels in testloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Update test loss\n            test_loss += loss.item() * inputs.size(0)\n\n            # Compute test accuracy\n            _, predicted = torch.max(outputs, 1)\n            test_total += labels.size(0)\n            test_correct += (predicted == labels).sum().item()\n\n    # Compute average test loss and accuracy\n    test_loss = test_loss / len(testloader.dataset)\n    test_accuracy = 100.0 * test_correct / test_total\n\n    return test_loss, test_accuracy","metadata":{"id":"mm8dq2mHiXFx","papermill":{"duration":0.01744,"end_time":"2023-06-19T06:15:18.734148","exception":false,"start_time":"2023-06-19T06:15:18.716708","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.477885Z","iopub.execute_input":"2024-05-27T07:51:30.478194Z","iopub.status.idle":"2024-05-27T07:51:30.486495Z","shell.execute_reply.started":"2024-05-27T07:51:30.478159Z","shell.execute_reply":"2024-05-27T07:51:30.485596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Iterating the Training\n\nThe “train_epochs” function trains the model for specified number of epochs and saves the best performing model. It returns the lists of losses and accuracies for train, and validation sets, which can be used to visualize the training and validation progress and evaluate the performance of the model. This can be used to decide when to stop training, and adjust the hyper-parameters like learning rate, batch size, etc.","metadata":{"id":"HqvThIm7zhW6","papermill":{"duration":0.007052,"end_time":"2023-06-19T06:15:18.748340","exception":false,"start_time":"2023-06-19T06:15:18.741288","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_epochs(model, trainloader, testloader, criterion, optimizer, device, num_epochs, save_interval=5):\n    train_losses = []\n    train_accuracies = []\n    test_losses = []\n    test_accuracies = []\n    best_accuracy = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        model, train_loss, train_accuracy = train(model, trainloader, criterion, optimizer, device)\n        test_loss, test_accuracy = test(model, testloader, criterion, device)\n\n        train_losses.append(train_loss)\n        train_accuracies.append(train_accuracy)\n        test_losses.append(test_loss)\n        test_accuracies.append(test_accuracy)\n\n        print(f'Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%')\n        print(f'Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%')\n        print()\n\n        # Save the model if the current test accuracy is higher than the best accuracy\n        if test_accuracy > best_accuracy:\n            best_accuracy = test_accuracy\n            checkpoint = {\n                'epoch' : epoch,\n                'model_state_dict' : model.state_dict(),\n                #'optimizer_state_dict': optimizer.state_dict(),\n                'test_accuracy' : test_accuracy\n            }\n            torch.save(checkpoint, 'best_model.pth')\n\n    return model, train_losses, train_accuracies, test_losses, test_accuracies","metadata":{"id":"S7Se4nmMiY3x","papermill":{"duration":0.018592,"end_time":"2023-06-19T06:15:18.774160","exception":false,"start_time":"2023-06-19T06:15:18.755568","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.487597Z","iopub.execute_input":"2024-05-27T07:51:30.487849Z","iopub.status.idle":"2024-05-27T07:51:30.496485Z","shell.execute_reply.started":"2024-05-27T07:51:30.487828Z","shell.execute_reply":"2024-05-27T07:51:30.495597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### FGSM Attack\n\nLet's define this function to run and compare the results of FGSM and PGD.","metadata":{}},{"cell_type":"code","source":"def fgsm_attack(model, criterion, images, labels, device, epsilon):\n    original_images = images.clone().detach().to(device)\n    \n    images.requires_grad_(True)\n    outputs = model(images)\n    loss = criterion(outputs, labels).to(device)\n    model.zero_grad()\n    loss.backward()\n    gradient = images.grad.data\n\n    perturbations = epsilon * torch.sign(gradient)\n    with torch.no_grad():\n        adversarial_images = images + perturbations\n        perturbations = torch.clamp(adversarial_images - original_images, min=-epsilon, max=epsilon)\n        adversarial_images = torch.clamp(original_images + perturbations, 0, 1)\n\n    return adversarial_images, perturbations","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:51:30.497645Z","iopub.execute_input":"2024-05-27T07:51:30.497916Z","iopub.status.idle":"2024-05-27T07:51:30.507342Z","shell.execute_reply.started":"2024-05-27T07:51:30.497895Z","shell.execute_reply":"2024-05-27T07:51:30.506371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Core of Projected Gradient Descent\nPGD attack is an iterative method that refines adversarial perturbations over multiple steps to generate stronger adversarial examples. Here’s a detailed breakdown of the PGD attack implementation:\n\n1. Initialization: \n* The original_images are cloned and detached to ensure they are not altered during the attack process. \n* adversarial_images are initialized as a copy of original_images and will be iteratively perturbed.\n\n\n2. Iterative Process: \n* For a specified number of iterations (num_iters), the following steps are performed:\n\n3. Setting Up Gradient Computation:\n* The requires_grad attribute of adversarial_images is set to True to enable gradient tracking.\n* A forward pass through the model is performed to obtain the model outputs for the current adversarial_images.\n\n4. Computing Loss:\n* The loss between the model outputs and the true labels is computed using the specified loss criterion.\n\n5. Clearing Previous Gradients:\n\n* Gradients are cleared to avoid accumulation from previous iterations.\n\n6. Backward Propagation:\n* Backward propagation is performed to compute the gradients of the loss with respect to adversarial_images.\n\n7. Updating Adversarial Images:\n* With torch.no_grad() to avoid tracking the updates, the gradients are retrieved from adversarial_images.grad.data.\n* The perturbation is computed by multiplying the gradient by the step size alpha and taking the sign of the result, indicating the direction to move in the input space.\n* adversarial_images are updated by adding this perturbation.\n\n8. Clamping Perturbations:\n* The perturbations are clamped to ensure they stay within the allowed epsilon-ball around the original images. This ensures the perturbations do not exceed the specified maximum magnitude (epsilon).\n* The updated adversarial_images are clamped to the valid image range [0, 1].\n\n9. Detaching Adversarial Images:\n* adversarial_images are detached from the current computation graph to avoid retaining unnecessary gradients in the next iteration.\n\n10. Returning Results:\n* After completing the specified number of iterations, the final adversarial images and perturbations are returned.\n\n","metadata":{"id":"4ws4HcM90Fxv","papermill":{"duration":0.006991,"end_time":"2023-06-19T06:15:18.787758","exception":false,"start_time":"2023-06-19T06:15:18.780767","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def pgd_attack(model, criterion, images, labels, device, epsilon, alpha, num_iters):\n    original_images = images.clone().detach().to(device)\n    adversarial_images = images.clone().detach().to(device)\n    \n    for _ in range(num_iters):\n        # Compute gradients within the loop\n        adversarial_images.requires_grad_(True)\n        outputs = model(adversarial_images)\n        loss = criterion(outputs, labels)\n            \n        model.zero_grad()\n        loss.backward()\n        \n        with torch.no_grad():\n            gradient = adversarial_images.grad.data\n            adversarial_images = adversarial_images + alpha * gradient.sign()\n            #perturbations = alpha * torch.sign(gradient)\n            \n            perturbations = torch.clamp(adversarial_images - original_images, min=-epsilon, max=epsilon)\n            adversarial_images = torch.clamp(original_images + perturbations, 0, 1)\n        \n        adversarial_images = adversarial_images.detach()\n    return adversarial_images, perturbations","metadata":{"id":"ijvBGHV4igJZ","papermill":{"duration":0.015357,"end_time":"2023-06-19T06:15:18.810186","exception":false,"start_time":"2023-06-19T06:15:18.794829","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.508844Z","iopub.execute_input":"2024-05-27T07:51:30.509481Z","iopub.status.idle":"2024-05-27T07:51:30.518311Z","shell.execute_reply.started":"2024-05-27T07:51:30.509450Z","shell.execute_reply":"2024-05-27T07:51:30.517566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing Robustness of ResNet-50 against PGD\n\nThe code below tests the accuracy of the fine-tuned ResNet-50 model against adversarial examples generated by PGD.\n\n* Adversarial Accuracy is defined by the percentage of images correctly classified by the model. This is a measure of the robustness of the model against the attack.\n* Attack Success Rate is measured as the percentage of\nadversarial images that are misclassified, among benign inputs that are correctly classified by the model. This is a measure of robustness of the attack against the model.","metadata":{"id":"M-XeWcTT3MVU","papermill":{"duration":0.006748,"end_time":"2023-06-19T06:15:18.823759","exception":false,"start_time":"2023-06-19T06:15:18.817011","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def test_adversarial(model, testloader, criterion, device, epsilon, alpha, num_iters, attack_type='PGD'):\n    adversarial_correct = 0\n    attack_success = 0\n    total = 0\n\n    model.eval()\n\n    for images, labels in testloader:\n        images, labels = images.to(device), labels.to(device)\n\n        if attack_type == 'PGD':\n            adversarial_images, _ = pgd_attack(model, criterion, images, labels, device, epsilon, alpha, num_iters)\n        elif attack_type == 'FGSM':\n            adversarial_images, _ = fgsm_attack(model, criterion, images, labels, device, epsilon)\n        else:\n            raise ValueError(\"Unknown attack type. Supported types: 'PGD', 'FGSM'\")\n\n        adversarial_outputs = model(adversarial_images)\n        _, adversarial_predicted = torch.max(adversarial_outputs.data, 1)\n\n        adversarial_correct += (adversarial_predicted == labels).sum().item()\n        attack_success += (adversarial_predicted != labels).sum().item()\n        total += labels.size(0)\n\n    adversarial_accuracy = 100.0 * adversarial_correct / total\n    attack_success_rate = 100.0 * attack_success / total\n    print(f'{attack_type} Attack - Epsilon = {epsilon}:')\n    print(f'Adversarial Accuracy: {adversarial_accuracy:.2f}%')\n    print(f'Attack Success Rate: {attack_success_rate:.2f}%')\n    print('------------------------------------------------------')\n    return adversarial_accuracy, attack_success_rate","metadata":{"id":"-FC7nEhVHYxE","papermill":{"duration":0.017308,"end_time":"2023-06-19T06:15:18.847879","exception":false,"start_time":"2023-06-19T06:15:18.830571","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.519554Z","iopub.execute_input":"2024-05-27T07:51:30.519885Z","iopub.status.idle":"2024-05-27T07:51:30.530833Z","shell.execute_reply.started":"2024-05-27T07:51:30.519855Z","shell.execute_reply":"2024-05-27T07:51:30.530039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing the Results","metadata":{"id":"aqFMIlfPz0pK","papermill":{"duration":0.006573,"end_time":"2023-06-19T06:15:18.861353","exception":false,"start_time":"2023-06-19T06:15:18.854780","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Plotting the Loss and Accuracy","metadata":{"papermill":{"duration":0.006927,"end_time":"2023-06-19T06:15:18.875215","exception":false,"start_time":"2023-06-19T06:15:18.868288","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_loss(train_losses, test_losses):\n    plt.figure()\n    plt.plot(range(len(train_losses)), train_losses, label='Training Loss')\n    plt.plot(range(len(test_losses)), test_losses, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('loss_plot.png')\n    plt.show()\n\n\ndef plot_accuracy(train_accuracies, test_accuracies):\n    plt.figure()\n    plt.plot(range(len(train_accuracies)), train_accuracies, label='Training Accuracy')\n    plt.plot(range(len(test_accuracies)), test_accuracies, label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.savefig('accuracy_plot.png')\n    plt.show()","metadata":{"id":"lx2Sdoueia0p","papermill":{"duration":0.016783,"end_time":"2023-06-19T06:15:18.898555","exception":false,"start_time":"2023-06-19T06:15:18.881772","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.531910Z","iopub.execute_input":"2024-05-27T07:51:30.532188Z","iopub.status.idle":"2024-05-27T07:51:30.541662Z","shell.execute_reply.started":"2024-05-27T07:51:30.532166Z","shell.execute_reply":"2024-05-27T07:51:30.540882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting an example prediction on clean","metadata":{"papermill":{"duration":0.00656,"end_time":"2023-06-19T06:15:18.911881","exception":false,"start_time":"2023-06-19T06:15:18.905321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_image(dataset, model, classes, device):\n    idx = random.randint(0, len(dataset))\n    label = dataset[idx][1]\n    img = dataset[idx][0].unsqueeze(0).to(device)  # Move the input image tensor to the GPU\n    model.eval()\n    output = model(img)\n    _, predicted = torch.max(output.data, 1)\n    # Convert the image and show it\n    img = img.squeeze().permute(1, 2, 0).cpu()  # Move the image tensor back to the CPU and adjust dimensions\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(f'Predicted: {classes[predicted]}, True: {classes[label]}')\n    plt.savefig('predicted_image.png')\n    plt.show()\n    print(\"Predicted label: \", classes[predicted[0].item()])\n    print(\"Actual label: \", classes[label])","metadata":{"id":"yK9tk3aPY0hp","papermill":{"duration":0.017577,"end_time":"2023-06-19T06:15:18.936851","exception":false,"start_time":"2023-06-19T06:15:18.919274","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.544046Z","iopub.execute_input":"2024-05-27T07:51:30.544304Z","iopub.status.idle":"2024-05-27T07:51:30.552720Z","shell.execute_reply.started":"2024-05-27T07:51:30.544284Z","shell.execute_reply":"2024-05-27T07:51:30.551900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting a few clean images along with their respective perturbations and adversarial examples.","metadata":{"papermill":{"duration":0.007018,"end_time":"2023-06-19T06:15:18.950386","exception":false,"start_time":"2023-06-19T06:15:18.943368","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nfrom torchvision.utils import make_grid\n\ndef plot_adv_images(testset, model, criterion, classes, device, epsilon_list, alpha=0.01, num_iters=10):\n    model.eval()\n    # Use first image from the testset for visualization\n    dataiter = iter(testset)\n    images, labels = dataiter.next()\n    images, labels = images.to(device), labels.to(device)\n    \n    # If epsilon_list is not a list, convert it to a list with a single element\n    if not isinstance(epsilon_list, list):\n        epsilon_list = [epsilon_list]\n\n    fig, axes = plt.subplots(len(epsilon_list) + 1, 1, figsize=(15, 10))\n    \n    # Plot original images\n    img_grid = make_grid(images.cpu().data, normalize=True)\n    axes[0].imshow(img_grid.permute(1, 2, 0))\n    axes[0].set_title(\"Original Images\")\n    axes[0].axis('off')\n    \n    for idx, epsilon in enumerate(epsilon_list):\n        adv_images = generate_adversarial_examples(images, labels, model, criterion, epsilon, alpha, num_iters, device)\n        img_grid_adv = make_grid(adv_images.cpu().data, normalize=True)\n        axes[idx + 1].imshow(img_grid_adv.permute(1, 2, 0))\n        axes[idx + 1].set_title(f\"Adversarial Images (Epsilon = {epsilon})\")\n        axes[idx + 1].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\ndef generate_adversarial_examples(images, labels, model, criterion, epsilon, alpha, num_iters, device):\n    images_adv = images.clone().detach().requires_grad_(True).to(device)\n    labels = labels.to(device)\n\n    for i in range(num_iters):\n        outputs = model(images_adv)\n        model.zero_grad()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        perturbation = alpha * images_adv.grad.sign()\n        images_adv = images_adv + perturbation\n        perturbation = torch.clamp(images_adv - images, min=-epsilon, max=epsilon)\n        images_adv = torch.clamp(images + perturbation, min=0, max=1).detach_()\n        images_adv.requires_grad = True\n\n    return images_adv","metadata":{"id":"PKnZHp64idfZ","papermill":{"duration":0.024975,"end_time":"2023-06-19T06:15:18.982589","exception":false,"start_time":"2023-06-19T06:15:18.957614","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.553725Z","iopub.execute_input":"2024-05-27T07:51:30.553947Z","iopub.status.idle":"2024-05-27T07:51:30.567817Z","shell.execute_reply.started":"2024-05-27T07:51:30.553928Z","shell.execute_reply":"2024-05-27T07:51:30.566781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plotting the line graph for Adversarial Accuracies and Attack Success Rates on adversarial data with varying epsilon values.","metadata":{"papermill":{"duration":0.006641,"end_time":"2023-06-19T06:15:18.996078","exception":false,"start_time":"2023-06-19T06:15:18.989437","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def epsilon_compare_multi(epsilon_values, adv_acc_pgd, att_succ_pgd, adv_acc_fgsm, att_succ_fgsm):\n    if len(epsilon_values) != len(adv_acc_pgd) or len(epsilon_values) != len(att_succ_pgd) or len(epsilon_values) != len(adv_acc_fgsm) or len(epsilon_values) != len(att_succ_fgsm):\n        print(\"Error: Input lists have different lengths.\")\n        return\n    \n    plt.figure(figsize=(10, 6))\n\n    plt.plot(epsilon_values, adv_acc_pgd, 'o-', label='PGD Adversarial Accuracy')\n    plt.plot(epsilon_values, att_succ_pgd, 'o-', label='PGD Attack Success Rate')\n    plt.plot(epsilon_values, adv_acc_fgsm, 'o-', label='FGSM Adversarial Accuracy')\n    plt.plot(epsilon_values, att_succ_fgsm, 'o-', label='FGSM Attack Success Rate')\n\n    for i in range(len(epsilon_values)):\n        plt.text(epsilon_values[i], adv_acc_pgd[i], f\"{adv_acc_pgd[i]:.2f}\", ha='center', va='bottom')\n        plt.text(epsilon_values[i], att_succ_pgd[i], f\"{att_succ_pgd[i]:.2f}\", ha='center', va='bottom')\n        plt.text(epsilon_values[i], adv_acc_fgsm[i], f\"{adv_acc_fgsm[i]:.2f}\", ha='center', va='bottom')\n        plt.text(epsilon_values[i], att_succ_fgsm[i], f\"{att_succ_fgsm[i]:.2f}\", ha='center', va='bottom')\n\n    plt.xlabel('Epsilon')\n    plt.ylabel('Percentage')\n    plt.title('Comparison of Adversarial Accuracies and Attack Success Rates between PGD and FGSM')\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig('epsilon_comparison.png')\n    plt.show()\n","metadata":{"papermill":{"duration":0.01762,"end_time":"2023-06-19T06:15:19.020161","exception":false,"start_time":"2023-06-19T06:15:19.002541","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.569080Z","iopub.execute_input":"2024-05-27T07:51:30.569393Z","iopub.status.idle":"2024-05-27T07:51:30.579459Z","shell.execute_reply.started":"2024-05-27T07:51:30.569365Z","shell.execute_reply":"2024-05-27T07:51:30.578704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Flow of Code\n\nThe seed is set for reproducibility. The dataset and model are loaded. The model's first convolutional layer is modified to suit CIFAR-10 dataset such that there is lesser loss of spatial information. The fully connected layer is also modified to suit CIFAR-10's 10 classes.\n\nThe loss function is CrossEntropy, optimizer is Stochastic Gradient Descent with a learning rate of 0.5, momentum of 0.9, epoch=60. The size of perturbation is set to 0.3.\n\nFirst the model is trained and the accuracy is calculated on the clean test set.\nThen the best model saved is loaded and tested against the adversarial examples. A list of epsilon values can be used to compare how the size of perturbation can affect the results. Finally, the adversarial examples are visualized.","metadata":{"id":"EGEPTWmU6sXj","papermill":{"duration":0.006436,"end_time":"2023-06-19T06:15:19.033278","exception":false,"start_time":"2023-06-19T06:15:19.026842","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def main(train_model, epsilon_list, alpha=0.01, num_iters=10):\n    # Set random seeds for reproducibility\n    random.seed(42)\n    np.random.seed(42)\n    torch.manual_seed(42)\n\n    # Load the dataset\n    num_classes = 10\n    batch_size = 64\n    trainset, trainloader, testset, testloader, classes = load_dataset(batch_size)\n\n    # Load the pre-trained model\n    model = models.resnet50(pretrained=True)\n    # Modify conv1 to suit CIFAR-10\n    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n    # Modify the final fully connected layer according to the number of classes\n    num_features = model.fc.in_features\n    model.fc = nn.Linear(num_features, num_classes)\n    # Move the model to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n\n    # Set hyperparameters\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    num_epochs = 60\n    # Default single epsilon value if no list is provided\n    epsilon_values = epsilon_list if epsilon_list else [0.3]  # Default to 0.3 if no epsilon_list is provided\n\n    if train_model:\n        print(\"Training the model...\")\n        # Train the model\n        model, train_losses, train_accuracies, test_losses, test_accuracies = train_epochs(\n            model, trainloader, testloader, criterion, optimizer, device, num_epochs)\n\n        # Plot the loss and accuracy curves\n        plot_loss(train_losses, test_losses)\n        plot_accuracy(train_accuracies, test_accuracies)\n        # Plot and save an example image\n        plot_image(testset, model, classes, device)\n        # Visualize some adversarial examples\n        print(\"Generating Visualization Plot\")\n        plot_adv_images(testset, model, criterion, classes, device, epsilon_values[0], alpha, num_iters)\n    else:\n        # Load the best model\n        best_model = models.resnet50(pretrained=True)\n        # Modify conv1 to suit CIFAR-10\n        best_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        best_model.fc = nn.Linear(num_features, num_classes)\n        # Load checkpoints\n        checkpoint = torch.load('/kaggle/input/best-model-cifar-10-resnet50/best_model.pth')\n        best_model.load_state_dict(checkpoint['model_state_dict'])\n        epoch = checkpoint['epoch']\n        test_accuracy = checkpoint['test_accuracy']\n        best_model = best_model.to(device)\n        print(\"Best Trained Model Loaded!\")\n        print(f\"Checkpoint at Epoch {epoch+1} with accuracy of {test_accuracy}%\")\n\n        # Test the best model on adversarial examples\n        if epsilon_list:\n            adversarial_accuracies_pgd = []\n            attack_success_rates_pgd = []\n            adversarial_accuracies_fgsm = []\n            attack_success_rates_fgsm = []\n            print(\"Testing with clean data again to compare with checkpoint accuracy...\")\n            _, clean_test_accuracy = test(best_model, testloader, criterion, device)\n            print(f\"Clean Test Accuracy: {clean_test_accuracy:.2f}%\\n\")\n            for epsilon in epsilon_values:\n                adv_acc_pgd, att_succ_pgd = test_adversarial(best_model, testloader, criterion, device, epsilon, alpha, num_iters, attack_type='PGD')\n                adversarial_accuracies_pgd.append(adv_acc_pgd)\n                attack_success_rates_pgd.append(att_succ_pgd)\n\n                adv_acc_fgsm, att_succ_fgsm = test_adversarial(best_model, testloader, criterion, device, epsilon, alpha, num_iters, attack_type='FGSM')\n                adversarial_accuracies_fgsm.append(adv_acc_fgsm)\n                attack_success_rates_fgsm.append(att_succ_fgsm)\n                \n                # Visualize adversarial examples for the current epsilon\n                print(f\"Generating Visualization Plot for epsilon = {epsilon}\")\n                plot_adv_images(testset, best_model, criterion, classes, device, epsilon, alpha, num_iters)\n\n            epsilon_compare_multi(epsilon_values, adversarial_accuracies_pgd, attack_success_rates_pgd, adversarial_accuracies_fgsm, attack_success_rates_fgsm)\n        else:\n            adv_acc_pgd, att_succ_pgd = test_adversarial(best_model, testloader, criterion, device, epsilon_values[0], alpha, num_iters, attack_type='PGD')\n            adv_acc_fgsm, att_succ_fgsm = test_adversarial(best_model, testloader, criterion, device, epsilon_values[0], alpha, num_iters, attack_type='FGSM')\n            print(f\"PGD - Adversarial Accuracy: {adv_acc_pgd}, Attack Success Rate: {att_succ_pgd}\")\n            print(f\"FGSM - Adversarial Accuracy: {adv_acc_fgsm}, Attack Success Rate: {att_succ_fgsm}\")\n            print(\"Generating Visualization Plot\")\n            plot_adv_images(testset, best_model, criterion, classes, device, epsilon_values[0], alpha, num_iters)\n","metadata":{"id":"tifWIFkBFEZV","papermill":{"duration":0.026181,"end_time":"2023-06-19T06:15:19.066213","exception":false,"start_time":"2023-06-19T06:15:19.040032","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.580621Z","iopub.execute_input":"2024-05-27T07:51:30.580908Z","iopub.status.idle":"2024-05-27T07:51:30.599104Z","shell.execute_reply.started":"2024-05-27T07:51:30.580886Z","shell.execute_reply":"2024-05-27T07:51:30.598335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The Main Function\n\nThe main() function is the entry point for the program.\n\nIf train_model is set to True, the function trains the model. The function first trains the model for num_epochs epochs. After each epoch, the function plots the loss and accuracy curves. The function then plots and saves an example image.\n\n* With train_model set to True, the function trains the model and visualizes the results with single epsilon value. \n\n### Effect of Perturbation Size\n\nIf train_model is set to False, the function loads the best model from a checkpoint.\n\n* If the \"episilon_list\" is set to None, the function  visualizes some adversarial examples.\n\n* If the \"episilon_list\" is set to True, the function uses a list of \"epsilon_values\" and runs the test_adversarial() function for all the values and then compares them.","metadata":{"id":"IpYApAYK6Zld","papermill":{"duration":0.006908,"end_time":"2023-06-19T06:15:19.079663","exception":false,"start_time":"2023-06-19T06:15:19.072755","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if __name__ == '__main__':\n    #main(train_model=True, epsilon_list=None)\n    main(train_model=False, epsilon_list=[0.01, 0.03, 0.07, 0.1, 0.3, 0.5], alpha=0.5, num_iters=20)","metadata":{"id":"IeNp45YaSFKH","outputId":"90ee8185-597f-41c7-97e0-165ede00997f","papermill":{"duration":3820.433601,"end_time":"2023-06-19T07:18:59.520525","exception":false,"start_time":"2023-06-19T06:15:19.086924","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-27T07:51:30.600162Z","iopub.execute_input":"2024-05-27T07:51:30.600405Z","iopub.status.idle":"2024-05-27T08:12:44.335524Z","shell.execute_reply.started":"2024-05-27T07:51:30.600384Z","shell.execute_reply":"2024-05-27T08:12:44.334677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}